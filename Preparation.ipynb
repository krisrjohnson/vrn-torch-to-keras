{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation\n",
    "First download the t7 file from http://cs.nott.ac.uk/~psxasj/download.php?file=vrn-unguided.t7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I use https://github.com/bshillingford/python-torchfile to parse the torch file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.insert(0, '../python-torchfile')\n",
    "import torchfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torchfile.load('vrn-unguided.t7')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the torch file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ln = 0\n",
    "list_file = open(\"list.txt\", \"w\")\n",
    "\n",
    "def lst(tobj, indent, f):\n",
    "    global ln\n",
    "    for module in tobj['modules']:\n",
    "        f.write(\"{}\\t{}{}\\t{}\\n\".format(ln,\n",
    "                                        \"    \" * indent,\n",
    "                                        module._typename,\n",
    "                                        module['weight'].shape \n",
    "                                            if 'weight' in module.__dir__() \n",
    "                                            else ''))\n",
    "        ln += 1\n",
    "        if 'modules' in module.__dir__():\n",
    "            lst(module, indent + 1, f)\n",
    "\n",
    "lst(t, 0, list_file)\n",
    "list_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Click [list.txt](./list.txt) to see the list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare torch layer to keras layer\n",
    "I want to be able to reference each layer by its line number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getr(tobj, ln):\n",
    "    for module in tobj['modules']:\n",
    "        if ln == 0:\n",
    "            return module, 0\n",
    "        ln -= 1\n",
    "        if 'modules' in module.__dir__():\n",
    "            got, ln = getr(module, ln)\n",
    "            if got is not None:\n",
    "                return got, 0\n",
    "\n",
    "    return None, ln\n",
    "\n",
    "def get(tobj, ln):\n",
    "    tout, _ = getr(tobj, ln)\n",
    "    return tout\n",
    "\n",
    "def info(module):\n",
    "    print(\"{}\".format(module._typename))\n",
    "    for prop in module.__dir__():\n",
    "        value = module[prop]\n",
    "        if value.__class__ == np.ndarray:\n",
    "            value = value.shape\n",
    "        if value.__class__ == list and len(value) > 0:\n",
    "            value = value[0].shape\n",
    "        print(\"{}\\t{}\".format(prop, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Conv layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nn.SpatialConvolution\n",
      "weight\t(64, 3, 7, 7)\n",
      "nOutputPlane\t64\n",
      "gradWeight\t(64, 3, 7, 7)\n",
      "bias\t(64,)\n",
      "nInputPlane\t3\n",
      "padH\t3\n",
      "padW\t3\n",
      "fgradInput\t(0,)\n",
      "_type\ttorch.FloatTensor\n",
      "finput\t(1, 147, 9216)\n",
      "fmode\t1\n",
      "kH\t7\n",
      "bwmode\t1\n",
      "train\tTrue\n",
      "kW\t7\n",
      "groups\t1\n",
      "gradBias\t(64,)\n",
      "dW\t2\n",
      "dH\t2\n",
      "gradInput\t(0,)\n",
      "bdmode\t1\n",
      "output\t(1, 64, 96, 96)\n",
      "torch_typename\tNone\n"
     ]
    }
   ],
   "source": [
    "info(get(t, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First BatchNorm layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nn.SpatialBatchNormalization\n",
      "save_mean\t(64,)\n",
      "_type\ttorch.FloatTensor\n",
      "running_mean\t(64,)\n",
      "weight\t(64,)\n",
      "train\tTrue\n",
      "affine\tTrue\n",
      "gradInput\t(0,)\n",
      "eps\t1e-05\n",
      "running_var\t(64,)\n",
      "gradWeight\t(64,)\n",
      "bias\t(64,)\n",
      "gradBias\t(64,)\n",
      "output\t(1, 64, 96, 96)\n",
      "save_std\t(64,)\n",
      "momentum\t0.1\n",
      "torch_typename\tNone\n"
     ]
    }
   ],
   "source": [
    "info(get(t, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note\n",
    "As I understand it, in Keras, when you run model.predict(), the Batch Norm layers use the saved running_mean and running_var values to normalize the data.<br>\n",
    "This is how I first tried to run this model, but it didn't work!<br>\n",
    "Finally, after a good amount of troubleshooting, I realized that the model would work if the Batch Norm layers were in train mode. Meaning, the mean and variance are updated each time.<br>\n",
    "So, I set training=True for each BN layer. I set momentum=1 to keep results consistent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build model in Keras\n",
    "[vrn_torch_to_keras.py](./vrn_torch_to_keras.py) is the script that parses vrn-unguided.t7, builds the Keras model, copies the weights, and then writes the h5 file."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
