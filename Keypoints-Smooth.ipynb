{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stabilize Landmark Points\n",
    "\n",
    "In this script, I stabilize the facial keypoints for the Tron video.\n",
    "To predict the keypoints, I use code from here: https://github.com/1adrianb/face-alignment\n",
    "\n",
    "My best results came from improving the quality of the keypoints for each frame. To do this, I augmented the input by flipping and rotating the original image.\n",
    "\n",
    "I rotated the image from -48 deg to 48 deg in 12 deg steps giving 9 images.\n",
    "Doing the same on the flipped image gives 18 total input images per frame.\n",
    "\n",
    "Finally, I average all of the results giving the improved keypoint predictions for that frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../face-alignment')\n",
    "import face_alignment\n",
    "from skimage import io\n",
    "import cv2\n",
    "import numpy as np\n",
    "import visvis as vv\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa = face_alignment.FaceAlignment(face_alignment.LandmarksType._3D, \n",
    "                                  enable_cuda=False, \n",
    "                                  flip_input=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    " def load_img(file_name):\n",
    "    img = cv2.imread(file_name)\n",
    "    if \"tron\" in file_name:\n",
    "        img = img[115:640, 763:1287, :]\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def screenshot(preds, img, output_file_name):\n",
    "    vv.clf()\n",
    "    \n",
    "    im = img\n",
    "    t = vv.imshow(im)\n",
    "    t.interpolate = True\n",
    "\n",
    "    x, y, z = np.array(zip(*(preds[0])))\n",
    "    \n",
    "    z = z + 100\n",
    "    \n",
    "    def plot(x, y, z, mc):\n",
    "        vv.plot(x, y, z, mc=mc, ls=\"\", ms=\".\", mw=3)\n",
    "    \n",
    "    a = 17\n",
    "    plot(x[:a], y[:a], z[:a], mc=(1, 0, 0))\n",
    "    \n",
    "    b = a + 10\n",
    "    plot(x[a:b], y[a:b], z[a:b], mc=(0, 1, 0))\n",
    "    \n",
    "    a, b = b, b + 9\n",
    "    plot(x[a:b], y[a:b], z[a:b], mc=(0, 0, 1))\n",
    "    \n",
    "    a, b = b, b + 6\n",
    "    plot(x[a:b], y[a:b], z[a:b], mc=(1, 1, 0))\n",
    "    \n",
    "    a, b = b, b + 6\n",
    "    plot(x[a:b], y[a:b], z[a:b], mc=(0, 1, 1))\n",
    "    \n",
    "    a, b = b, b + 12\n",
    "    plot(x[a:b], y[a:b], z[a:b], mc=(.5, 1, .2))\n",
    "    \n",
    "    plot(x[b:], y[b:], z[b:], mc=(1, 0, 1))\n",
    "\n",
    "    a = vv.gca()\n",
    "    a.camera.fov = 0 # orthographic\n",
    "    a.camera.azimuth = 0\n",
    "    a.camera.elevation = 90\n",
    "    a.camera.roll = 0\n",
    "\n",
    "    if output_file_name is None:\n",
    "        vv.use().Run()\n",
    "    else:\n",
    "        vv.screenshot(output_file_name, vv.gcf(), sf=2, bg='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/6802577/python-rotation-of-3d-vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotation_matrix(axis, theta):\n",
    "    \"\"\"\n",
    "    Return the rotation matrix associated with counterclockwise rotation about\n",
    "    the given axis by theta radians.\n",
    "    \"\"\"\n",
    "    axis = np.asarray(axis)\n",
    "    axis = axis/math.sqrt(np.dot(axis, axis))\n",
    "    a = math.cos(theta/2.0)\n",
    "    b, c, d = -axis*math.sin(theta/2.0)\n",
    "    aa, bb, cc, dd = a*a, b*b, c*c, d*d\n",
    "    bc, ad, ac, ab, bd, cd = b*c, a*d, a*c, a*b, b*d, c*d\n",
    "    return np.array([[aa+bb-cc-dd, 2*(bc+ad), 2*(bd-ac)],\n",
    "                     [2*(bc-ad), aa+cc-bb-dd, 2*(cd+ab)],\n",
    "                     [2*(bd+ac), 2*(cd-ab), aa+dd-bb-cc]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate(img, d):\n",
    "    rows,cols, _ = img.shape\n",
    "    M = cv2.getRotationMatrix2D((cols/2,rows/2),d,1)\n",
    "    dst = cv2.warpAffine(img,M,(cols,rows))\n",
    "    return dst\n",
    "\n",
    "def augments(img):\n",
    "    rows,cols, _ = img.shape\n",
    "    for d in range(-48, 49, 12):\n",
    "        theta = d * math.pi / 180.0\n",
    "        rot_img = rotate(img, d)\n",
    "        r = rotation_matrix((0, 0, -1), -theta)\n",
    "        \n",
    "        def reverse(pred):\n",
    "            offset = (cols/2.0, rows/2.0, 0)\n",
    "            pred[0] = np.dot(pred[0] - offset, r.T) + offset\n",
    "            return pred\n",
    "        \n",
    "        yield rot_img, reverse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get all the predictions for a frame and then average them together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keypoints(file_name, flip=False):\n",
    "    img = load_img(file_name)\n",
    "    if flip:\n",
    "        img = cv2.flip(img, 1)\n",
    "    img_pred = np.zeros((1, 68, 3))\n",
    "    n = 0\n",
    "    for rot_img, reverse in augments(img):\n",
    "        pred = fa.get_landmarks(rot_img)\n",
    "        if pred is not None:\n",
    "            pred = reverse(pred)\n",
    "            img_pred[0] = img_pred[0] + pred[0]\n",
    "            n += 1\n",
    "    img_pred[0] = img_pred[0] / float(n)\n",
    "    if flip:\n",
    "        img_pred[0,:,0] = img.shape[0] - img_pred[0,:,0]\n",
    "    return img_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = \"/Users/paul/Downloads/tron_frames\"\n",
    "preds = [get_keypoints(\"{}/frame{:04d}.jpg\".format(dir, i)) \n",
    "         for i in tqdm(range(1, 101))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bfffa9efa2148e38fa5248bfcf4e06c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in Jupyter Notebook or JupyterLab, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another notebook frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=88), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "Warning: No faces were detected.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds_flip = [get_keypoints(\"{}/frame{:04d}.jpg\".format(dir, i), \n",
    "                            flip=True) \n",
    "              for i in tqdm(range(1, 101))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flip_keypoints(pred):\n",
    "    tmp_pred = np.copy(pred)\n",
    "    a = 17\n",
    "    tmp_pred[:a] = pred[:a][::-1]\n",
    "    \n",
    "    b = a + 10\n",
    "    tmp_pred[a:b] = pred[a:b][::-1]\n",
    "    \n",
    "    b += 4\n",
    "    \n",
    "    a, b = b, b + 5\n",
    "    tmp_pred[a:b] = pred[a:b][::-1]\n",
    "    \n",
    "    a = b\n",
    "    \n",
    "    tmp_pred[a:a+4], \n",
    "    tmp_pred[a+6:a+10] = pred[a+6:a+10][::-1], pred[a:a+4][::-1]\n",
    "    \n",
    "    tmp_pred[a+4:a+6],\n",
    "    tmp_pred[a+10:a+12] = pred[a+10:a+12][::-1], pred[a+4:a+6][::-1]\n",
    "    \n",
    "    a, b = a + 12, b + 19\n",
    "    tmp_pred[a:b] = pred[a:b][::-1]\n",
    "    \n",
    "    a, b = b, b + 5\n",
    "    tmp_pred[a:b] = pred[a:b][::-1]\n",
    "    \n",
    "    a, b = b, b + 5\n",
    "    tmp_pred[a:b] = pred[a:b][::-1]\n",
    "    \n",
    "    a, b = b, b + 3\n",
    "    tmp_pred[a:b] = pred[a:b][::-1]\n",
    "                          \n",
    "    return tmp_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot copy sequence with size 2 to array axis with dimension 4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-28937097b26c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m88\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mpreds_flip\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflip_keypoints\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds_flip\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-517da6be7628>\u001b[0m in \u001b[0;36mflip_keypoints\u001b[0;34m(pred)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mtmp_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mtmp_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mtmp_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot copy sequence with size 2 to array axis with dimension 4"
     ]
    }
   ],
   "source": [
    "for i in range(88):\n",
    "    preds_flip[i,0] = flip_keypoints(preds_flip[i,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Average the original and flipped predictions together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_smooth = (preds[:,0,:,:] + preds_flip[:,0,:,:]) / 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_smooth = np.array(preds)[:,0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-3f1b699855d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpreds_smooth\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreds_smooth\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "preds_smooth[:,0,:,2] = preds_smooth[:,0,:,2] + 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_smooth[:,:,2] = preds_smooth[:,:,2] + 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('keypoints_preds_smooth', np.array(preds_smooth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 101):\n",
    "    img = load_img(\"{}/frame{:04d}.jpg\".format(dir, i))\n",
    "    pred = preds_smooth[i - 1]\n",
    "    screenshot([pred], img, \"tron_keyframes_smooth/frame{:04d}.jpg\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paul/miniconda2/lib/python2.7/site-packages/imageio/core/util.py:78: UserWarning: Lossy conversion from float32 to uint8, range [0, 1]\n",
      "  dtype_str, out_type.__name__))\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 89):\n",
    "    img = load_img(\"{}/frame{:04d}.jpg\".format(dir, i))\n",
    "    pred = preds_smooth[i - 1]\n",
    "    screenshot([pred], img, \"leia_keyframes_smooth/frame{:04d}.jpg\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wCEABALDBoYFhoYGRodHRodHR4dHR0dHyYXHR0dLicxMC0n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\nAAAAAAAAAAAAAAAAAAAAAAAP/9k=\n",
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"400\"\n",
       "            height=\"300\"\n",
       "            src=\"https://www.youtube.com/embed/q5jAZuFcqlQ\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.YouTubeVideo at 0x10ebb3f10>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.lib.display import YouTubeVideo\n",
    "YouTubeVideo('q5jAZuFcqlQ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I do some preperation for the face swap script, I use the same method as above to get keypoints for the face I will swap into the tron video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(525, 524, 3)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = load_img(\"/Users/paul/Downloads/tron_frames/frame0001.jpg\")\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = get_keypoints(\"joey.jpg\")\n",
    "pred_flip = get_keypoints(\"joey.jpg\", flip=True)\n",
    "pred_flip[0] = flip_keypoints(pred_flip[0])\n",
    "pred_smooth = (pred[0] + pred_flip[0]) / 2.0\n",
    "np.save('joey_keypoints.npy', pred_smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(639, 639, 3)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = load_img(\"joey.jpg\")\n",
    "img.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
